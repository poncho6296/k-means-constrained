{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-6f81aec4968b>, line 175)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-6f81aec4968b>\"\u001b[1;36m, line \u001b[1;32m175\u001b[0m\n\u001b[1;33m    labels, inertia, centers, n_iter_ =\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"K-means clustering\"\"\"\n",
    "\n",
    "# Authors: Josh Levy-Kramer <josh@outra.co.uk>\n",
    "#          Gael Varoquaux <gael.varoquaux@normalesup.org>\n",
    "#          Thomas Rueckstiess <ruecksti@in.tum.de>\n",
    "#          James Bergstra <james.bergstra@umontreal.ca>\n",
    "#          Jan Schlueter <scikit-learn@jan-schlueter.de>\n",
    "#          Nelle Varoquaux\n",
    "#          Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#          Robert Layton <robertlayton@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from .sklearn_import.metrics.pairwise import euclidean_distances\n",
    "from .sklearn_import.utils.extmath import row_norms, squared_norm, cartesian\n",
    "from .sklearn_import.utils.validation import check_array, check_random_state, as_float_array\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "\n",
    "# Internal scikit learn methods imported into this project\n",
    "from k_means_constrained.sklearn_import.cluster._k_means import _centers_dense, _centers_sparse\n",
    "from k_means_constrained.sklearn_import.cluster.k_means_ import _validate_center_shape, _tolerance, KMeans, _init_centroids\n",
    "\n",
    "from k_means_constrained.mincostflow_vectorized import SimpleMinCostFlowVectorized\n",
    "\n",
    "\n",
    "def k_means_constrained(X,W, n_clusters, size_min=None, size_max=None, init='k-means++',\n",
    "            n_init=10, max_iter=300, verbose=False,\n",
    "            tol=1e-4, random_state=None, copy_x=True, n_jobs=1,\n",
    "            return_n_iter=False):\n",
    "    \"\"\"K-Means clustering with minimum and maximum cluster size constraints.\n",
    "\n",
    "    Read more in the :ref:`User Guide <k_means>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The observations to cluster.\n",
    "\n",
    "    size_min : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a minimum\n",
    "        size of size_min. If None, no constrains will be applied\n",
    "\n",
    "    size_max : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a maximum\n",
    "        size of size_max. If None, no constrains will be applied\n",
    "\n",
    "    n_clusters : int\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "\n",
    "    init : {'k-means++', 'random', or ndarray, or a callable}, optional\n",
    "        Method for initialization, default to 'k-means++':\n",
    "\n",
    "        'k-means++' : selects initial cluster centers for k-mean\n",
    "        clustering in a smart way to speed up convergence. See section\n",
    "        Notes in k_init for more details.\n",
    "\n",
    "        'random': generate k centroids from a Gaussian with mean and\n",
    "        variance estimated from the data.\n",
    "\n",
    "        If an ndarray is passed, it should be of shape (n_clusters, n_features)\n",
    "        and gives the initial centers.\n",
    "\n",
    "        If a callable is passed, it should take arguments X, k and\n",
    "        and a random state and return an initialization.\n",
    "\n",
    "    n_init : int, optional, default: 10\n",
    "        Number of time the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "\n",
    "    max_iter : int, optional, default 300\n",
    "        Maximum number of iterations of the k-means algorithm to run.\n",
    "\n",
    "    verbose : boolean, optional\n",
    "        Verbosity mode.\n",
    "\n",
    "    tol : float, optional\n",
    "        The relative increment in the results before declaring convergence.\n",
    "\n",
    "    random_state : int, RandomState instance or None, optional, default: None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    copy_x : boolean, optional\n",
    "        When pre-computing distances it is more numerically accurate to center\n",
    "        the data first.  If copy_x is True, then the original data is not\n",
    "        modified.  If False, the original data is modified, and put back before\n",
    "        the function returns, but small numerical differences may be introduced\n",
    "        by subtracting and then adding the data mean.\n",
    "\n",
    "    n_jobs : int\n",
    "        The number of jobs to use for the computation. This works by computing\n",
    "        each of the n_init runs in parallel.\n",
    "\n",
    "        If -1 all CPUs are used. If 1 is given, no parallel computing code is\n",
    "        used at all, which is useful for debugging. For n_jobs below -1,\n",
    "        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one\n",
    "        are used.\n",
    "\n",
    "    return_n_iter : bool, optional\n",
    "        Whether or not to return the number of iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    centroid : float ndarray with shape (k, n_features)\n",
    "        Centroids found at the last iteration of k-means.\n",
    "\n",
    "    label : integer ndarray with shape (n_samples,)\n",
    "        label[i] is the code or index of the centroid the\n",
    "        i'th observation is closest to.\n",
    "\n",
    "    inertia : float\n",
    "        The final value of the inertia criterion (sum of squared distances to\n",
    "        the closest centroid for all observations in the training set).\n",
    "\n",
    "    best_n_iter : int\n",
    "        Number of iterations corresponding to the best results.\n",
    "        Returned only if `return_n_iter` is set to True.\n",
    "\n",
    "    \"\"\"\n",
    "    if sp.issparse(X):\n",
    "        raise NotImplementedError(\"Not implemented for sparse X\")\n",
    "\n",
    "    if n_init <= 0:\n",
    "        raise ValueError(\"Invalid number of initializations.\"\n",
    "                         \" n_init=%d must be bigger than zero.\" % n_init)\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    if max_iter <= 0:\n",
    "        raise ValueError('Number of iterations should be a positive number,'\n",
    "                         ' got %d instead' % max_iter)\n",
    "\n",
    "    X = as_float_array(X, copy=copy_x)\n",
    "    tol = _tolerance(X, tol)\n",
    "\n",
    "    # Validate init array\n",
    "    if hasattr(init, '__array__'):\n",
    "        init = check_array(init, dtype=X.dtype.type, copy=True)\n",
    "        _validate_center_shape(X, n_clusters, init)\n",
    "\n",
    "        if n_init != 1:\n",
    "            warnings.warn(\n",
    "                'Explicit initial center position passed: '\n",
    "                'performing only one init in k-means instead of n_init=%d'\n",
    "                % n_init, RuntimeWarning, stacklevel=2)\n",
    "            n_init = 1\n",
    "\n",
    "    # subtract of mean of x for more accurate distance computations\n",
    "    if not sp.issparse(X):\n",
    "        X_mean = X.mean(axis=0)\n",
    "        # The copy was already done above\n",
    "        X -= X_mean\n",
    "\n",
    "        if hasattr(init, '__array__'):\n",
    "            init -= X_mean\n",
    "\n",
    "    # precompute squared norms of data points\n",
    "    x_squared_norms = row_norms(X, squared=True)\n",
    "\n",
    "    best_labels, best_inertia, best_centers = None, None, None\n",
    "\n",
    "    if n_jobs == 1:\n",
    "        # For a single thread, less memory is needed if we just store one set\n",
    "        # of the best results (as opposed to one set per run per thread).\n",
    "        for it in range(n_init):\n",
    "            # run a k-means once\n",
    "            labels, inertia, centers, n_iter_ = \n",
    "            (\n",
    "                X,W, n_clusters,\n",
    "                size_min=size_min, size_max=size_max,\n",
    "                max_iter=max_iter, init=init, verbose=verbose, tol=tol,\n",
    "                x_squared_norms=x_squared_norms, random_state=random_state)\n",
    "            # determine if these results are the best so far\n",
    "            if best_inertia is None or inertia < best_inertia:\n",
    "                best_labels = labels.copy()\n",
    "                best_centers = centers.copy()\n",
    "                best_inertia = inertia\n",
    "                best_n_iter = n_iter_\n",
    "    else:\n",
    "        # parallelisation of k-means runs\n",
    "        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n",
    "        results = Parallel(n_jobs=n_jobs, verbose=0)(\n",
    "            delayed(kmeans_constrained_single)(X,W, n_clusters,\n",
    "                                   size_min=size_min, size_max=size_max,\n",
    "                                   max_iter=max_iter, init=init,\n",
    "                                   verbose=verbose, tol=tol,\n",
    "                                   x_squared_norms=x_squared_norms,\n",
    "                                   # Change seed to ensure variety\n",
    "                                   random_state=seed)\n",
    "            for seed in seeds)\n",
    "        # Get results with the lowest inertia\n",
    "        labels, inertia, centers, n_iters = zip(*results)\n",
    "        best = np.argmin(inertia)\n",
    "        best_labels = labels[best]\n",
    "        best_inertia = inertia[best]\n",
    "        best_centers = centers[best]\n",
    "        best_n_iter = n_iters[best]\n",
    "\n",
    "    if not sp.issparse(X):\n",
    "        if not copy_x:\n",
    "            X += X_mean\n",
    "        best_centers += X_mean\n",
    "\n",
    "    if return_n_iter:\n",
    "        return best_centers, best_labels, best_inertia, best_n_iter\n",
    "    else:\n",
    "        return best_centers, best_labels, best_inertia\n",
    "\n",
    "\n",
    "def kmeans_constrained_single(X,W, n_clusters, size_min=None, size_max=None,\n",
    "                         max_iter=300, init='k-means++',\n",
    "                         verbose=False, x_squared_norms=None,\n",
    "                         random_state=None, tol=1e-4):\n",
    "    \"\"\"A single run of k-means constrained, assumes preparation completed prior.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like of floats, shape (n_samples, n_features)\n",
    "        The observations to cluster.\n",
    "\n",
    "    size_min : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a minimum\n",
    "        size of size_min. If None, no constrains will be applied\n",
    "\n",
    "    size_max : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a maximum\n",
    "        size of size_max. If None, no constrains will be applied\n",
    "\n",
    "    n_clusters : int\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "\n",
    "    max_iter : int, optional, default 300\n",
    "        Maximum number of iterations of the k-means algorithm to run.\n",
    "\n",
    "    init : {'k-means++', 'random', or ndarray, or a callable}, optional\n",
    "        Method for initialization, default to 'k-means++':\n",
    "\n",
    "        'k-means++' : selects initial cluster centers for k-mean\n",
    "        clustering in a smart way to speed up convergence. See section\n",
    "        Notes in k_init for more details.\n",
    "\n",
    "        'random': generate k centroids from a Gaussian with mean and\n",
    "        variance estimated from the data.\n",
    "\n",
    "        If an ndarray is passed, it should be of shape (k, p) and gives\n",
    "        the initial centers.\n",
    "\n",
    "        If a callable is passed, it should take arguments X, k and\n",
    "        and a random state and return an initialization.\n",
    "\n",
    "    tol : float, optional\n",
    "        The relative increment in the results before declaring convergence.\n",
    "\n",
    "    verbose : boolean, optional\n",
    "        Verbosity mode\n",
    "\n",
    "    x_squared_norms : array\n",
    "        Precomputed x_squared_norms.\n",
    "\n",
    "    random_state : int, RandomState instance or None, optional, default: None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    centroid : float ndarray with shape (k, n_features)\n",
    "        Centroids found at the last iteration of k-means.\n",
    "\n",
    "    label : integer ndarray with shape (n_samples,)\n",
    "        label[i] is the code or index of the centroid the\n",
    "        i'th observation is closest to.\n",
    "\n",
    "    inertia : float\n",
    "        The final value of the inertia criterion (sum of squared distances to\n",
    "        the closest centroid for all observations in the training set).\n",
    "\n",
    "    n_iter : int\n",
    "        Number of iterations run.\n",
    "    \"\"\"\n",
    "    if sp.issparse(X):\n",
    "        raise NotImplementedError(\"Not implemented for sparse X\")\n",
    "\n",
    "    random_state = check_random_state(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    best_labels, best_inertia, best_centers = None, None, None\n",
    "    # init\n",
    "    centers = _init_centroids(X, n_clusters, init, random_state=random_state, x_squared_norms=x_squared_norms)\n",
    "    if verbose:\n",
    "        print(\"Initialization complete\")\n",
    "\n",
    "    # Allocate memory to store the distances for each sample to its\n",
    "    # closer center for reallocation in case of ties\n",
    "    distances = np.zeros(shape=(n_samples,), dtype=X.dtype)\n",
    "\n",
    "    # Determine min and max sizes if non given\n",
    "    if size_min is None:\n",
    "        size_min = 0\n",
    "    if size_max is None:\n",
    "        size_max = n_samples  # Number of data points\n",
    "\n",
    "    # Check size min and max\n",
    "    if not ((size_min >= 0) and (size_min <= n_samples)\n",
    "            and (size_max >= 0) and (size_max <= n_samples)):\n",
    "        raise ValueError(\"size_min and size_max must be a positive number smaller \"\n",
    "                         \"than the number of data points or `None`\")\n",
    "    if size_max < size_min:\n",
    "        raise ValueError(\"size_max must be larger than size_min\")\n",
    "    if size_min*n_clusters > n_samples:\n",
    "        raise ValueError(\"The product of size_min and n_clusters cannot exceed the number of samples (X)\")\n",
    "\n",
    "    # iterations\n",
    "    for i in range(max_iter):\n",
    "        centers_old = centers.copy()\n",
    "        # labels assignment is also called the E-step of EM\n",
    "        labels, inertia = \\\n",
    "            _labels_constrained(X, centers, size_min, size_max, distances=distances)\n",
    "\n",
    "        # computation of the means is also called the M-step of EM\n",
    "        if sp.issparse(X):\n",
    "            centers = _centers_sparse(X, labels, n_clusters, distances)\n",
    "        else:\n",
    "            centers = _centers_dense(X,W, labels, n_clusters, distances)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Iteration %2d, inertia %.3f\" % (i, inertia))\n",
    "\n",
    "        if best_inertia is None or inertia < best_inertia:\n",
    "            best_labels = labels.copy()\n",
    "            best_centers = centers.copy()\n",
    "            best_inertia = inertia\n",
    "\n",
    "        center_shift_total = squared_norm(centers_old - centers)\n",
    "        if center_shift_total <= tol:\n",
    "            if verbose:\n",
    "                print(\"Converged at iteration %d: \"\n",
    "                      \"center shift %e within tolerance %e\"\n",
    "                      % (i, center_shift_total, tol))\n",
    "            break\n",
    "\n",
    "    if center_shift_total > 0:\n",
    "        # rerun E-step in case of non-convergence so that predicted labels\n",
    "        # match cluster centers\n",
    "        best_labels, best_inertia = \\\n",
    "            _labels_constrained(X, centers, size_min, size_max, distances=distances)\n",
    "\n",
    "    return best_labels, best_inertia, best_centers, i + 1\n",
    "\n",
    "\n",
    "def _labels_constrained(X, centers, size_min, size_max, distances):\n",
    "    \"\"\"Compute labels using the min and max cluster size constraint\n",
    "\n",
    "    This will overwrite the 'distances' array in-place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (n_sample, n_features)\n",
    "        Input data.\n",
    "\n",
    "    size_min : int\n",
    "        Minimum size for each cluster\n",
    "\n",
    "    size_max : int\n",
    "        Maximum size for each cluster\n",
    "\n",
    "    centers : numpy array, shape (n_clusters, n_features)\n",
    "        Cluster centers which data is assigned to.\n",
    "\n",
    "    distances : numpy array, shape (n_samples,)\n",
    "        Pre-allocated array in which distances are stored.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : numpy array, dtype=np.int, shape (n_samples,)\n",
    "        Indices of clusters that samples are assigned to.\n",
    "\n",
    "    inertia : float\n",
    "        Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "    \"\"\"\n",
    "    C = centers\n",
    "\n",
    "    # Distances to each centre C. (the `distances` parameter is the distance to the closest centre)\n",
    "    # K-mean original uses squared distances but this equivalent for constrained k-means\n",
    "    D = euclidean_distances(X, C, squared=False)\n",
    "\n",
    "    edges, costs, capacities, supplies, n_C, n_X = minimum_cost_flow_problem_graph(X, C, D, size_min, size_max)\n",
    "    labels = solve_min_cost_flow_graph(edges, costs, capacities, supplies, n_C, n_X)\n",
    "\n",
    "    # cython k-means M step code assumes int32 inputs\n",
    "    labels = labels.astype(np.int32)\n",
    "\n",
    "    # Change distances in-place\n",
    "    distances[:] = D[np.arange(D.shape[0]), labels]**2  # Square for M step of EM\n",
    "    inertia = distances.sum()\n",
    "\n",
    "    return labels, inertia\n",
    "\n",
    "\n",
    "def minimum_cost_flow_problem_graph(X, C, D, size_min, size_max):\n",
    "\n",
    "    # Setup minimum cost flow formulation graph\n",
    "    # Vertices indexes:\n",
    "    # X-nodes: [0, n(x)-1], C-nodes: [n(X), n(X)+n(C)-1], C-dummy nodes:[n(X)+n(C), n(X)+2*n(C)-1],\n",
    "    # Artificial node: [n(X)+2*n(C), n(X)+2*n(C)+1-1]\n",
    "\n",
    "    # Create indices of nodes\n",
    "    n_X = X.shape[0]\n",
    "    n_C = C.shape[0]\n",
    "    X_ix = np.arange(n_X)\n",
    "    C_dummy_ix = np.arange(X_ix[-1] + 1, X_ix[-1] + 1 + n_C)\n",
    "    C_ix = np.arange(C_dummy_ix[-1] + 1, C_dummy_ix[-1] + 1 + n_C)\n",
    "    art_ix = C_ix[-1] + 1\n",
    "\n",
    "    # Edges\n",
    "    edges_X_C_dummy = cartesian([X_ix, C_dummy_ix])  # All X's connect to all C dummy nodes (C')\n",
    "    edges_C_dummy_C = np.stack([C_dummy_ix, C_ix], axis=1)  # Each C' connects to a corresponding C (centroid)\n",
    "    edges_C_art = np.stack([C_ix, art_ix * np.ones(n_C)], axis=1)  # All C connect to artificial node\n",
    "\n",
    "    edges = np.concatenate([edges_X_C_dummy, edges_C_dummy_C, edges_C_art])\n",
    "\n",
    "    # Costs\n",
    "    costs_X_C_dummy = D.reshape(D.size)\n",
    "    costs = np.concatenate([costs_X_C_dummy, np.zeros(edges.shape[0] - len(costs_X_C_dummy))])\n",
    "\n",
    "    # Capacities - can set for max-k\n",
    "    capacities_C_dummy_C = size_max * np.ones(n_C)\n",
    "    cap_non = n_X  # The total supply and therefore wont restrict flow\n",
    "    capacities = np.concatenate([\n",
    "        np.ones(edges_X_C_dummy.shape[0]),\n",
    "        capacities_C_dummy_C,\n",
    "        cap_non * np.ones(n_C)\n",
    "    ])\n",
    "\n",
    "    # Sources and sinks\n",
    "    supplies_X = np.ones(n_X)\n",
    "    supplies_C = -1 * size_min * np.ones(n_C)  # Demand node\n",
    "    supplies_art = -1 * (n_X - n_C*size_min)  # Demand node\n",
    "    supplies = np.concatenate([\n",
    "        supplies_X,\n",
    "        np.zeros(n_C),  # C_dummies\n",
    "        supplies_C,\n",
    "        [supplies_art]\n",
    "    ])\n",
    "\n",
    "    # All arrays must be of int dtype for `SimpleMinCostFlow`\n",
    "    edges = edges.astype('int32')\n",
    "    costs = np.around(costs*1000, 0).astype('int32')  # Times by 1000 to give extra precision\n",
    "    capacities = capacities.astype('int32')\n",
    "    supplies = supplies.astype('int32')\n",
    "\n",
    "    return edges, costs, capacities, supplies, n_C, n_X\n",
    "\n",
    "\n",
    "def solve_min_cost_flow_graph(edges, costs, capacities, supplies, n_C, n_X):\n",
    "\n",
    "    # Instantiate a SimpleMinCostFlow solver.\n",
    "    min_cost_flow = SimpleMinCostFlowVectorized()\n",
    "\n",
    "    if (edges.dtype != 'int32') or (costs.dtype != 'int32') \\\n",
    "            or (capacities.dtype != 'int32') or (supplies.dtype != 'int32'):\n",
    "        raise ValueError(\"`edges`, `costs`, `capacities`, `supplies` must all be int dtype\")\n",
    "\n",
    "    N_edges = edges.shape[0]\n",
    "    N_nodes = len(supplies)\n",
    "\n",
    "    # Add each edge with associated capacities and cost\n",
    "    min_cost_flow.AddArcWithCapacityAndUnitCostVectorized(edges[:,0], edges[:,1], capacities, costs)\n",
    "\n",
    "    # Add node supplies\n",
    "    min_cost_flow.SetNodeSupplyVectorized(np.arange(N_nodes, dtype='int32'), supplies)\n",
    "\n",
    "    # Find the minimum cost flow between node 0 and node 4.\n",
    "    if min_cost_flow.Solve() != min_cost_flow.OPTIMAL:\n",
    "        raise Exception('There was an issue with the min cost flow input.')\n",
    "\n",
    "    # Assignment\n",
    "    labels_M = min_cost_flow.FlowVectorized(np.arange(n_X * n_C, dtype='int32')).reshape(n_X, n_C)\n",
    "\n",
    "    labels = labels_M.argmax(axis=1)\n",
    "    return labels\n",
    "\n",
    "\n",
    "class KMeansConstrained(KMeans):\n",
    "    \"\"\"K-Means clustering with minimum and maximum cluster size constraints\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    n_clusters : int, optional, default: 8\n",
    "        The number of clusters to form as well as the number of\n",
    "        centroids to generate.\n",
    "\n",
    "    size_min : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a minimum\n",
    "        size of size_min. If None, no constrains will be applied\n",
    "\n",
    "    size_max : int, optional, default: None\n",
    "        Constrain the label assignment so that each cluster has a maximum\n",
    "        size of size_max. If None, no constrains will be applied\n",
    "\n",
    "    init : {'k-means++', 'random' or an ndarray}\n",
    "        Method for initialization, defaults to 'k-means++':\n",
    "\n",
    "        'k-means++' : selects initial cluster centers for k-mean\n",
    "        clustering in a smart way to speed up convergence. See section\n",
    "        Notes in k_init for more details.\n",
    "\n",
    "        'random': choose k observations (rows) at random from data for\n",
    "        the initial centroids.\n",
    "\n",
    "        If an ndarray is passed, it should be of shape (n_clusters, n_features)\n",
    "        and gives the initial centers.\n",
    "\n",
    "    n_init : int, default: 10\n",
    "        Number of times the k-means algorithm will be run with different\n",
    "        centroid seeds. The final results will be the best output of\n",
    "        n_init consecutive runs in terms of inertia.\n",
    "\n",
    "    max_iter : int, default: 300\n",
    "        Maximum number of iterations of the k-means algorithm for a\n",
    "        single run.\n",
    "\n",
    "    tol : float, default: 1e-4\n",
    "        Relative tolerance with regards to inertia to declare convergence\n",
    "\n",
    "    verbose : int, default 0\n",
    "        Verbosity mode.\n",
    "\n",
    "    random_state : int, RandomState instance or None, optional, default: None\n",
    "        If int, random_state is the seed used by the random number generator;\n",
    "        If RandomState instance, random_state is the random number generator;\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by `np.random`.\n",
    "\n",
    "    copy_x : boolean, default True\n",
    "        When pre-computing distances it is more numerically accurate to center\n",
    "        the data first.  If copy_x is True, then the original data is not\n",
    "        modified.  If False, the original data is modified, and put back before\n",
    "        the function returns, but small numerical differences may be introduced\n",
    "        by subtracting and then adding the data mean.\n",
    "\n",
    "    n_jobs : int\n",
    "        The number of jobs to use for the computation. This works by computing\n",
    "        each of the n_init runs in parallel.\n",
    "\n",
    "        If -1 all CPUs are used. If 1 is given, no parallel computing code is\n",
    "        used at all, which is useful for debugging. For n_jobs below -1,\n",
    "        (n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one\n",
    "        are used.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    cluster_centers_ : array, [n_clusters, n_features]\n",
    "        Coordinates of cluster centers\n",
    "\n",
    "    labels_ :\n",
    "        Labels of each point\n",
    "\n",
    "    inertia_ : float\n",
    "        Sum of squared distances of samples to their closest cluster center.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "\n",
    "    >>> from k_means_constrained import KMeansConstrained\n",
    "    >>> import numpy as np\n",
    "    >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "    ...               [4, 2], [4, 4], [4, 0]])\n",
    "    >>> clf = KMeansConstrained(n_clusters=2, size_min=2, size_max=5, random_state=0).fit(X)\n",
    "    >>> clf.labels_\n",
    "    array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
    "    >>> clf.predict([[0, 0], [4, 4]])\n",
    "    array([0, 1], dtype=int32)\n",
    "    >>> clf.cluster_centers_\n",
    "    array([[ 1.,  2.],\n",
    "           [ 4.,  2.]])\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    K-means problem constrained with a minimum and/or maximum size for each cluster.\n",
    "\n",
    "    The constrained assignment is formulated as a Minimum Cost Flow (MCF) linear network optimisation\n",
    "    problem. This is then solved using a cost-scaling push-relabel algorithm. The implementation used is\n",
    "     Google's Operations Research tools's `SimpleMinCostFlow`.\n",
    "\n",
    "    Ref:\n",
    "    1. Bradley, P. S., K. P. Bennett, and Ayhan Demiriz. \"Constrained k-means clustering.\"\n",
    "        Microsoft Research, Redmond (2000): 1-8.\n",
    "    2. Google's SimpleMinCostFlow implementation:\n",
    "        https://github.com/google/or-tools/blob/master/ortools/graph/min_cost_flow.h\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters=8, size_min=None, size_max=None, init='k-means++', n_init=10, max_iter=300, tol=1e-4,\n",
    "                 verbose=False, random_state=None, copy_x=True, n_jobs=1):\n",
    "\n",
    "        self.size_min = size_min\n",
    "        self.size_max = size_max\n",
    "\n",
    "        super().__init__(n_clusters=n_clusters, init=init, n_init=n_init, max_iter=max_iter, tol=tol,\n",
    "                         verbose=verbose, random_state=random_state, copy_x=copy_x, n_jobs=n_jobs)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Compute k-means clustering.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape=(n_samples, n_features)\n",
    "            Training instances to cluster.\n",
    "\n",
    "        y : Ignored\n",
    "\n",
    "        \"\"\"\n",
    "        if sp.issparse(X):\n",
    "            raise NotImplementedError(\"Not implemented for sparse X\")\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        X = self._check_fit_data(X)\n",
    "\n",
    "        self.cluster_centers_, self.labels_, self.inertia_, self.n_iter_ = \\\n",
    "            k_means_constrained(\n",
    "                X, n_clusters=self.n_clusters,\n",
    "                size_min=self.size_min, size_max=self.size_max,\n",
    "                init=self.init,\n",
    "                n_init=self.n_init, max_iter=self.max_iter, verbose=self.verbose,\n",
    "                tol=self.tol, random_state=random_state, copy_x=self.copy_x,\n",
    "                n_jobs=self.n_jobs,\n",
    "                return_n_iter=True)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
